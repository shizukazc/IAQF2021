{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAQF 2021 Code Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_NO = 3\n",
    "PERIOD_NO = 'p2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sbn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>crude_oil</th>\n",
       "      <th>cpi</th>\n",
       "      <th>coal_consumption</th>\n",
       "      <th>ngas_consumption</th>\n",
       "      <th>us_pop</th>\n",
       "      <th>oil_production</th>\n",
       "      <th>cattle_index</th>\n",
       "      <th>tree_cover_loss</th>\n",
       "      <th>us_real_gdp</th>\n",
       "      <th>usd_mex_exrate</th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>42.40</td>\n",
       "      <td>93.262178</td>\n",
       "      <td>80527.66971</td>\n",
       "      <td>1.166511e+06</td>\n",
       "      <td>306035.0</td>\n",
       "      <td>4935</td>\n",
       "      <td>297.27</td>\n",
       "      <td>1406957.794</td>\n",
       "      <td>14476.2498</td>\n",
       "      <td>13.657700</td>\n",
       "      <td>386.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-11</td>\n",
       "      <td>44.46</td>\n",
       "      <td>91.817169</td>\n",
       "      <td>81500.87953</td>\n",
       "      <td>9.357362e+05</td>\n",
       "      <td>306085.5</td>\n",
       "      <td>4917</td>\n",
       "      <td>288.70</td>\n",
       "      <td>1567991.001</td>\n",
       "      <td>16075.1555</td>\n",
       "      <td>13.899500</td>\n",
       "      <td>387.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-18</td>\n",
       "      <td>36.73</td>\n",
       "      <td>91.122475</td>\n",
       "      <td>97916.98177</td>\n",
       "      <td>9.389947e+05</td>\n",
       "      <td>306136.0</td>\n",
       "      <td>5052</td>\n",
       "      <td>299.23</td>\n",
       "      <td>1336297.836</td>\n",
       "      <td>15137.1916</td>\n",
       "      <td>14.025100</td>\n",
       "      <td>387.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-25</td>\n",
       "      <td>42.15</td>\n",
       "      <td>87.888142</td>\n",
       "      <td>84498.02661</td>\n",
       "      <td>9.046054e+05</td>\n",
       "      <td>306186.5</td>\n",
       "      <td>5045</td>\n",
       "      <td>292.83</td>\n",
       "      <td>1652557.380</td>\n",
       "      <td>15155.3440</td>\n",
       "      <td>14.255700</td>\n",
       "      <td>387.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-01</td>\n",
       "      <td>42.70</td>\n",
       "      <td>82.715265</td>\n",
       "      <td>89510.77745</td>\n",
       "      <td>7.992948e+05</td>\n",
       "      <td>306237.0</td>\n",
       "      <td>5235</td>\n",
       "      <td>290.44</td>\n",
       "      <td>1470782.481</td>\n",
       "      <td>15538.1713</td>\n",
       "      <td>14.119200</td>\n",
       "      <td>387.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>58.07</td>\n",
       "      <td>112.084710</td>\n",
       "      <td>43325.23094</td>\n",
       "      <td>6.060118e+05</td>\n",
       "      <td>329314.0</td>\n",
       "      <td>12900</td>\n",
       "      <td>430.72</td>\n",
       "      <td>2173871.578</td>\n",
       "      <td>19477.3091</td>\n",
       "      <td>19.286699</td>\n",
       "      <td>411.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>57.64</td>\n",
       "      <td>109.471205</td>\n",
       "      <td>39751.66796</td>\n",
       "      <td>8.286665e+05</td>\n",
       "      <td>329335.8</td>\n",
       "      <td>12800</td>\n",
       "      <td>426.54</td>\n",
       "      <td>2458219.683</td>\n",
       "      <td>19750.1111</td>\n",
       "      <td>18.997499</td>\n",
       "      <td>411.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>59.25</td>\n",
       "      <td>108.183411</td>\n",
       "      <td>48847.79099</td>\n",
       "      <td>7.519214e+05</td>\n",
       "      <td>329357.6</td>\n",
       "      <td>12800</td>\n",
       "      <td>435.32</td>\n",
       "      <td>1946025.679</td>\n",
       "      <td>20106.3904</td>\n",
       "      <td>18.938499</td>\n",
       "      <td>411.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>60.75</td>\n",
       "      <td>108.707988</td>\n",
       "      <td>50008.88542</td>\n",
       "      <td>5.915937e+05</td>\n",
       "      <td>329379.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>429.35</td>\n",
       "      <td>2230631.393</td>\n",
       "      <td>20396.2701</td>\n",
       "      <td>18.844700</td>\n",
       "      <td>412.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>61.29</td>\n",
       "      <td>105.725844</td>\n",
       "      <td>49428.07791</td>\n",
       "      <td>6.146294e+05</td>\n",
       "      <td>329401.2</td>\n",
       "      <td>12900</td>\n",
       "      <td>432.42</td>\n",
       "      <td>2124357.069</td>\n",
       "      <td>18812.8854</td>\n",
       "      <td>18.911301</td>\n",
       "      <td>412.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           week  crude_oil         cpi  coal_consumption  ngas_consumption  \\\n",
       "0    2009-01-04      42.40   93.262178       80527.66971      1.166511e+06   \n",
       "1    2009-01-11      44.46   91.817169       81500.87953      9.357362e+05   \n",
       "2    2009-01-18      36.73   91.122475       97916.98177      9.389947e+05   \n",
       "3    2009-01-25      42.15   87.888142       84498.02661      9.046054e+05   \n",
       "4    2009-02-01      42.70   82.715265       89510.77745      7.992948e+05   \n",
       "..          ...        ...         ...               ...               ...   \n",
       "569  2019-12-01      58.07  112.084710       43325.23094      6.060118e+05   \n",
       "570  2019-12-08      57.64  109.471205       39751.66796      8.286665e+05   \n",
       "571  2019-12-15      59.25  108.183411       48847.79099      7.519214e+05   \n",
       "572  2019-12-22      60.75  108.707988       50008.88542      5.915937e+05   \n",
       "573  2019-12-29      61.29  105.725844       49428.07791      6.146294e+05   \n",
       "\n",
       "       us_pop  oil_production  cattle_index  tree_cover_loss  us_real_gdp  \\\n",
       "0    306035.0            4935        297.27      1406957.794   14476.2498   \n",
       "1    306085.5            4917        288.70      1567991.001   16075.1555   \n",
       "2    306136.0            5052        299.23      1336297.836   15137.1916   \n",
       "3    306186.5            5045        292.83      1652557.380   15155.3440   \n",
       "4    306237.0            5235        290.44      1470782.481   15538.1713   \n",
       "..        ...             ...           ...              ...          ...   \n",
       "569  329314.0           12900        430.72      2173871.578   19477.3091   \n",
       "570  329335.8           12800        426.54      2458219.683   19750.1111   \n",
       "571  329357.6           12800        435.32      1946025.679   20106.3904   \n",
       "572  329379.4           12900        429.35      2230631.393   20396.2701   \n",
       "573  329401.2           12900        432.42      2124357.069   18812.8854   \n",
       "\n",
       "     usd_mex_exrate     co2  \n",
       "0         13.657700  386.40  \n",
       "1         13.899500  387.02  \n",
       "2         14.025100  387.14  \n",
       "3         14.255700  387.50  \n",
       "4         14.119200  387.03  \n",
       "..              ...     ...  \n",
       "569       19.286699  411.07  \n",
       "570       18.997499  411.32  \n",
       "571       18.938499  411.89  \n",
       "572       18.844700  412.21  \n",
       "573       18.911301  412.99  \n",
       "\n",
       "[574 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OS = 'Mac'  # OS is either 'Mac' or 'Windows'\n",
    "sep = '/' if OS == 'Mac' else '\\\\'\n",
    "path = \"..{}source_data{}{}.csv\"\n",
    "\n",
    "PROBLEM_PATH_DICT = {\n",
    "    1: {\n",
    "        'basic': path.format(sep, sep, \"crude_gas_et_df\"),\n",
    "        'et': path.format(sep, sep, \"crude_gas_et_df\"),\n",
    "        'p1': path.format(sep, sep, \"crude_gas_p1_df\"),\n",
    "        'p1.2': path.format(sep, sep, \"crude_gas_p2_df\"),\n",
    "        'p2': path.format(sep, sep, \"crude_gas_p2_df\")\n",
    "    },  # crude oil price vs. gasoline price\n",
    "    2: {\n",
    "        'basic': path.format(sep, sep, \"cf_gas_et_df\"),\n",
    "        'et': path.format(sep, sep, \"cf_gas_et_df\"),\n",
    "        'p1': path.format(sep, sep, \"cf_gas_p1_df\"),\n",
    "        'p1.2': path.format(sep, sep, \"cf_gas_p2_df\"),\n",
    "        'p2': path.format(sep, sep, \"cf_gas_p2_df\"),\n",
    "    },  # crude oil futures price vs. gasoline price\n",
    "    3: {\n",
    "        'basic': path.format(sep, sep, \"crude_co2_et_df\"),\n",
    "        'et': path.format(sep, sep, \"crude_co2_et_df\"),\n",
    "        'p1': path.format(sep, sep, \"crude_co2_p1_df\"),\n",
    "        'p1.2': path.format(sep, sep, \"crude_co2_p2_df\"),\n",
    "        'p2': path.format(sep, sep, \"crude_co2_p2_df\")\n",
    "    }  # crude oil price vs. co2\n",
    "}\n",
    "\n",
    "PROBLEM_VAR_DICT = {\n",
    "    1: ('crude_oil', 'gasoline'),\n",
    "    2: ('oil_futures', 'gasoline'),\n",
    "    3: ('crude_oil', 'co2')\n",
    "}\n",
    "\n",
    "ADDITIONAL_VAR_DICT = {\n",
    "    1: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1.2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','djus_auto_index','auto_sales','us_real_gdp','usd_mex_exrate']\n",
    "        \n",
    "    },\n",
    "    2: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1.2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','djus_auto_index','auto_sales','us_real_gdp','usd_mex_exrate']\n",
    "\n",
    "    },\n",
    "    3: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p1': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p1.2': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p2': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','cattle_index','tree_cover_loss','us_real_gdp','usd_mex_exrate']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sheetname = str(PROBLEM_NO) + PERIOD_NO\n",
    "\n",
    "X_MAIN_COL, Y_COL = PROBLEM_VAR_DICT[PROBLEM_NO]\n",
    "X_MAIN_CHG_COL = X_MAIN_COL + '_chg'\n",
    "Y_CHG_COL = Y_COL + '_chg'\n",
    "EXTRA_VARS = ADDITIONAL_VAR_DICT[PROBLEM_NO][PERIOD_NO]\n",
    "\n",
    "TRAINING_RATIO_DEFAULT = 0.7\n",
    "VALIDATION_RATIO_DEFAULT = 0.15\n",
    "TEST_RATIO_DEFAULT = 0.15\n",
    "\n",
    "REGRESSOR_ACCURACY_DICT = {}\n",
    "CLASSIFIER_ACCURACY_DICT = {}\n",
    "\n",
    "REGRESSOR_COEF_DICT = {}\n",
    "CLASSIFIER_COEF_DICT = {}\n",
    "\n",
    "df = pd.read_csv(PROBLEM_PATH_DICT[PROBLEM_NO][PERIOD_NO])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>crude_oil</th>\n",
       "      <th>cpi</th>\n",
       "      <th>coal_consumption</th>\n",
       "      <th>ngas_consumption</th>\n",
       "      <th>us_pop</th>\n",
       "      <th>oil_production</th>\n",
       "      <th>cattle_index</th>\n",
       "      <th>tree_cover_loss</th>\n",
       "      <th>us_real_gdp</th>\n",
       "      <th>usd_mex_exrate</th>\n",
       "      <th>co2</th>\n",
       "      <th>crude_oil_chg_1</th>\n",
       "      <th>crude_oil_chg_2</th>\n",
       "      <th>crude_oil_chg_3</th>\n",
       "      <th>crude_oil_chg_5</th>\n",
       "      <th>crude_oil_chg_10</th>\n",
       "      <th>co2_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2009-03-22</td>\n",
       "      <td>49.49</td>\n",
       "      <td>93.593485</td>\n",
       "      <td>88029.33328</td>\n",
       "      <td>607862.7477</td>\n",
       "      <td>306562.2</td>\n",
       "      <td>5432</td>\n",
       "      <td>282.76</td>\n",
       "      <td>1933223.874</td>\n",
       "      <td>15121.9490</td>\n",
       "      <td>14.338800</td>\n",
       "      <td>389.29</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.146132</td>\n",
       "      <td>0.204136</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.113135</td>\n",
       "      <td>0.002808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2009-03-29</td>\n",
       "      <td>52.99</td>\n",
       "      <td>105.508484</td>\n",
       "      <td>81588.96621</td>\n",
       "      <td>786643.0421</td>\n",
       "      <td>306603.6</td>\n",
       "      <td>5480</td>\n",
       "      <td>278.41</td>\n",
       "      <td>1451331.110</td>\n",
       "      <td>15312.9473</td>\n",
       "      <td>13.541800</td>\n",
       "      <td>389.04</td>\n",
       "      <td>0.070721</td>\n",
       "      <td>0.160534</td>\n",
       "      <td>0.227189</td>\n",
       "      <td>0.426380</td>\n",
       "      <td>0.442690</td>\n",
       "      <td>-0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>50.34</td>\n",
       "      <td>97.283677</td>\n",
       "      <td>72928.73097</td>\n",
       "      <td>389615.9568</td>\n",
       "      <td>306645.0</td>\n",
       "      <td>5469</td>\n",
       "      <td>287.29</td>\n",
       "      <td>1181283.104</td>\n",
       "      <td>15389.4132</td>\n",
       "      <td>13.130000</td>\n",
       "      <td>389.43</td>\n",
       "      <td>-0.050009</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>0.102497</td>\n",
       "      <td>0.224818</td>\n",
       "      <td>0.194306</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>50.46</td>\n",
       "      <td>79.216384</td>\n",
       "      <td>72626.84388</td>\n",
       "      <td>553381.6950</td>\n",
       "      <td>306699.5</td>\n",
       "      <td>5482</td>\n",
       "      <td>288.74</td>\n",
       "      <td>1278670.711</td>\n",
       "      <td>14744.1587</td>\n",
       "      <td>13.097800</td>\n",
       "      <td>388.93</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>-0.047745</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.168597</td>\n",
       "      <td>0.181733</td>\n",
       "      <td>-0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2009-04-19</td>\n",
       "      <td>49.86</td>\n",
       "      <td>95.223458</td>\n",
       "      <td>69962.81952</td>\n",
       "      <td>351902.9953</td>\n",
       "      <td>306754.0</td>\n",
       "      <td>5421</td>\n",
       "      <td>288.48</td>\n",
       "      <td>1752394.499</td>\n",
       "      <td>14624.3705</td>\n",
       "      <td>13.550500</td>\n",
       "      <td>389.56</td>\n",
       "      <td>-0.011891</td>\n",
       "      <td>-0.009535</td>\n",
       "      <td>-0.059068</td>\n",
       "      <td>0.091984</td>\n",
       "      <td>0.222658</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>58.07</td>\n",
       "      <td>112.084710</td>\n",
       "      <td>43325.23094</td>\n",
       "      <td>606011.7971</td>\n",
       "      <td>329314.0</td>\n",
       "      <td>12900</td>\n",
       "      <td>430.72</td>\n",
       "      <td>2173871.578</td>\n",
       "      <td>19477.3091</td>\n",
       "      <td>19.286699</td>\n",
       "      <td>411.07</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.021460</td>\n",
       "      <td>0.024343</td>\n",
       "      <td>0.051993</td>\n",
       "      <td>-0.021237</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>57.64</td>\n",
       "      <td>109.471205</td>\n",
       "      <td>39751.66796</td>\n",
       "      <td>828666.4868</td>\n",
       "      <td>329335.8</td>\n",
       "      <td>12800</td>\n",
       "      <td>426.54</td>\n",
       "      <td>2458219.683</td>\n",
       "      <td>19750.1111</td>\n",
       "      <td>18.997499</td>\n",
       "      <td>411.32</td>\n",
       "      <td>-0.007405</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.044771</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>59.25</td>\n",
       "      <td>108.183411</td>\n",
       "      <td>48847.79099</td>\n",
       "      <td>751921.3538</td>\n",
       "      <td>329357.6</td>\n",
       "      <td>12800</td>\n",
       "      <td>435.32</td>\n",
       "      <td>1946025.679</td>\n",
       "      <td>20106.3904</td>\n",
       "      <td>18.938499</td>\n",
       "      <td>411.89</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.115399</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>60.75</td>\n",
       "      <td>108.707988</td>\n",
       "      <td>50008.88542</td>\n",
       "      <td>591593.7371</td>\n",
       "      <td>329379.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>429.35</td>\n",
       "      <td>2230631.393</td>\n",
       "      <td>20396.2701</td>\n",
       "      <td>18.844700</td>\n",
       "      <td>412.21</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.053956</td>\n",
       "      <td>0.046151</td>\n",
       "      <td>0.068602</td>\n",
       "      <td>0.140417</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>61.29</td>\n",
       "      <td>105.725844</td>\n",
       "      <td>49428.07791</td>\n",
       "      <td>614629.4116</td>\n",
       "      <td>329401.2</td>\n",
       "      <td>12900</td>\n",
       "      <td>432.42</td>\n",
       "      <td>2124357.069</td>\n",
       "      <td>18812.8854</td>\n",
       "      <td>18.911301</td>\n",
       "      <td>412.99</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.034430</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>0.077153</td>\n",
       "      <td>0.145822</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           week  crude_oil         cpi  coal_consumption  ngas_consumption  \\\n",
       "11   2009-03-22      49.49   93.593485       88029.33328       607862.7477   \n",
       "12   2009-03-29      52.99  105.508484       81588.96621       786643.0421   \n",
       "13   2009-04-05      50.34   97.283677       72928.73097       389615.9568   \n",
       "14   2009-04-12      50.46   79.216384       72626.84388       553381.6950   \n",
       "15   2009-04-19      49.86   95.223458       69962.81952       351902.9953   \n",
       "..          ...        ...         ...               ...               ...   \n",
       "569  2019-12-01      58.07  112.084710       43325.23094       606011.7971   \n",
       "570  2019-12-08      57.64  109.471205       39751.66796       828666.4868   \n",
       "571  2019-12-15      59.25  108.183411       48847.79099       751921.3538   \n",
       "572  2019-12-22      60.75  108.707988       50008.88542       591593.7371   \n",
       "573  2019-12-29      61.29  105.725844       49428.07791       614629.4116   \n",
       "\n",
       "       us_pop  oil_production  cattle_index  tree_cover_loss  us_real_gdp  \\\n",
       "11   306562.2            5432        282.76      1933223.874   15121.9490   \n",
       "12   306603.6            5480        278.41      1451331.110   15312.9473   \n",
       "13   306645.0            5469        287.29      1181283.104   15389.4132   \n",
       "14   306699.5            5482        288.74      1278670.711   14744.1587   \n",
       "15   306754.0            5421        288.48      1752394.499   14624.3705   \n",
       "..        ...             ...           ...              ...          ...   \n",
       "569  329314.0           12900        430.72      2173871.578   19477.3091   \n",
       "570  329335.8           12800        426.54      2458219.683   19750.1111   \n",
       "571  329357.6           12800        435.32      1946025.679   20106.3904   \n",
       "572  329379.4           12900        429.35      2230631.393   20396.2701   \n",
       "573  329401.2           12900        432.42      2124357.069   18812.8854   \n",
       "\n",
       "     usd_mex_exrate     co2  crude_oil_chg_1  crude_oil_chg_2  \\\n",
       "11        14.338800  389.29         0.083881         0.146132   \n",
       "12        13.541800  389.04         0.070721         0.160534   \n",
       "13        13.130000  389.43        -0.050009         0.017175   \n",
       "14        13.097800  388.93         0.002384        -0.047745   \n",
       "15        13.550500  389.56        -0.011891        -0.009535   \n",
       "..              ...     ...              ...              ...   \n",
       "569       19.286699  411.07         0.020562         0.021460   \n",
       "570       18.997499  411.32        -0.007405         0.013005   \n",
       "571       18.938499  411.89         0.027932         0.020320   \n",
       "572       18.844700  412.21         0.025316         0.053956   \n",
       "573       18.911301  412.99         0.008889         0.034430   \n",
       "\n",
       "     crude_oil_chg_3  crude_oil_chg_5  crude_oil_chg_10   co2_chg  \n",
       "11          0.204136         0.339740          0.113135  0.002808  \n",
       "12          0.227189         0.426380          0.442690 -0.000642  \n",
       "13          0.102497         0.224818          0.194306  0.001002  \n",
       "14          0.019600         0.168597          0.181733 -0.001284  \n",
       "15         -0.059068         0.091984          0.222658  0.001620  \n",
       "..               ...              ...               ...       ...  \n",
       "569         0.024343         0.051993         -0.021237  0.000852  \n",
       "570         0.013896         0.044771          0.013005  0.000608  \n",
       "571         0.041301         0.045158          0.115399  0.001386  \n",
       "572         0.046151         0.068602          0.140417  0.000777  \n",
       "573         0.063324         0.077153          0.145822  0.001892  \n",
       "\n",
       "[563 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate independent variables\n",
    "periods = (1,2,3,5,10)\n",
    "for i in periods:\n",
    "    df [X_MAIN_CHG_COL + f'_{i}'] = df[X_MAIN_COL].pct_change(periods=i)\n",
    "\n",
    "# calculate dependent variable\n",
    "df[Y_CHG_COL] = df[Y_COL].pct_change(periods=1)\n",
    "\n",
    "# eliminate the empty rows\n",
    "df = df[11:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.94900000e+01,  8.38808585e-02,  1.46132469e-01, ...,\n",
       "         1.93322387e+06,  1.51219490e+04,  1.43388004e+01],\n",
       "       [ 5.29900000e+01,  7.07213579e-02,  1.60534385e-01, ...,\n",
       "         1.45133111e+06,  1.53129473e+04,  1.35417996e+01],\n",
       "       [ 5.03400000e+01, -5.00094357e-02,  1.71751869e-02, ...,\n",
       "         1.18128310e+06,  1.53894132e+04,  1.31300001e+01],\n",
       "       ...,\n",
       "       [ 5.92500000e+01,  2.79319917e-02,  2.03203031e-02, ...,\n",
       "         1.94602568e+06,  2.01063904e+04,  1.89384994e+01],\n",
       "       [ 6.07500000e+01,  2.53164557e-02,  5.39555864e-02, ...,\n",
       "         2.23063139e+06,  2.03962701e+04,  1.88446999e+01],\n",
       "       [ 6.12900000e+01,  8.88888889e-03,  3.44303797e-02, ...,\n",
       "         2.12435707e+06,  1.88128854e+04,  1.89113007e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of independent variable's name\n",
    "indep_vars = [X_MAIN_CHG_COL + f'_{i}' for i in periods] + EXTRA_VARS\n",
    "num_var =len(indep_vars)\n",
    "\n",
    "# extract the values to X\n",
    "X = df[[X_MAIN_COL] + indep_vars].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((563, 15), (563,), (563,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create y for regressor, y_c for classifier\n",
    "y = df[Y_CHG_COL]\n",
    "y_c = (df[Y_CHG_COL] > 0).values.astype('int')\n",
    "\n",
    "# set training, validation, and test criterias\n",
    "training_ratio = TRAINING_RATIO_DEFAULT\n",
    "validation_ratio = VALIDATION_RATIO_DEFAULT\n",
    "test_ratio = TEST_RATIO_DEFAULT\n",
    "\n",
    "# check correctness of X and y\n",
    "X.shape, y.shape, y_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (393, 15)\n",
      "X_test shape:\t (85, 15)\n",
      "X_val shape:\t (85, 15)\n",
      "y_train shape:\t (393,)\n",
      "y_val shape:\t (85,)\n",
      "y_test shape:\t (85,)\n"
     ]
    }
   ],
   "source": [
    "# create training, validation, and test sets for regressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=42)\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_test shape:\\t\", X_test.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_c shape: (393, 15)\n",
      "X_test_c shape:\t (85, 15)\n",
      "X_val_c shape:\t (85, 15)\n",
      "y_train_c shape: (393,)\n",
      "y_val_c shape:\t (85,)\n",
      "y_test_c shape:\t (85,)\n"
     ]
    }
   ],
   "source": [
    "# create training, validation, and test sets for classifier\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_c, test_size=test_ratio, random_state=42)\n",
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_train_c, y_train_c, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=42)\n",
    "\n",
    "print(\"X_train_c shape:\", X_train_c.shape)\n",
    "print(\"X_test_c shape:\\t\", X_test_c.shape)\n",
    "print(\"X_val_c shape:\\t\", X_val_c.shape)\n",
    "print(\"y_train_c shape:\", y_train_c.shape)\n",
    "print(\"y_val_c shape:\\t\", y_val_c.shape)\n",
    "print(\"y_test_c shape:\\t\", y_test_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (393, 15)\n",
      "X_val shape:\t (85, 15)\n"
     ]
    }
   ],
   "source": [
    "# normalization for regressor set\n",
    "for i in range(X_train.shape[1]):\n",
    "    X_train_mean = X_train[:, i]. mean()\n",
    "    X_train_std = X_train[:, i].std()\n",
    "    X_train[:, i] = (X_train[:,i] - X_train_mean) / X_train_std\n",
    "    X_test[:,i] = (X_test[:,i] - X_train_mean) / X_train_std\n",
    "    X_val[:, i] = (X_val[:,i] - X_train_mean) / X_train_std\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_c shape: (393, 15)\n",
      "X_val_c shape:\t (85, 15)\n"
     ]
    }
   ],
   "source": [
    "# normalization for classifier set\n",
    "for i in range(X_train_c.shape[1]):\n",
    "    X_train_c_mean = X_train_c[:, i]. mean()\n",
    "    X_train_c_std = X_train_c[:, i].std()\n",
    "    X_train_c[:, i] = (X_train_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "    X_test_c[:,i] = (X_test_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "    X_val_c[:, i] = (X_val_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "\n",
    "print(\"X_train_c shape:\", X_train_c.shape)\n",
    "print(\"X_val_c shape:\\t\", X_val_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca shape:\t (393, 9)\n",
      "X_test_pca shape:\t (85, 9)\n",
      "X_val_pca shape:\t (85, 9)\n",
      "y_train shape:\t (393,)\n",
      "y_val shape:\t (85,)\n",
      "y_test shape:\t (85,)\n"
     ]
    }
   ],
   "source": [
    "# PCA for regressor\n",
    "# set PCA value\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# fit PCA training set\n",
    "pca.fit(X_train)\n",
    "\n",
    "# apply transform to training and test set\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(\"X_train_pca shape:\\t\", X_train_pca.shape)\n",
    "print(\"X_test_pca shape:\\t\", X_test_pca.shape)\n",
    "print(\"X_val_pca shape:\\t\", X_val_pca.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_c_pca shape:\t (393, 9)\n",
      "X_test_c_pca shape:\t (85, 9)\n",
      "X_val_c_pca shape:\t (85, 9)\n",
      "y_train_c shape: (393,)\n",
      "y_val_c shape:\t (85,)\n",
      "y_test_c shape:\t (85,)\n"
     ]
    }
   ],
   "source": [
    "# PCA for classifier\n",
    "# apply transform to training and test set\n",
    "X_train_c_pca = pca.transform(X_train_c)\n",
    "X_test_c_pca = pca.transform(X_test_c)\n",
    "X_val_c_pca = pca.transform(X_val_c)\n",
    "\n",
    "print(\"X_train_c_pca shape:\\t\", X_train_c_pca.shape)\n",
    "print(\"X_test_c_pca shape:\\t\", X_test_c_pca.shape)\n",
    "print(\"X_val_c_pca shape:\\t\", X_val_c_pca.shape)\n",
    "print(\"y_train_c shape:\", y_train_c.shape)\n",
    "print(\"y_val_c shape:\\t\", y_val_c.shape)\n",
    "print(\"y_test_c shape:\\t\", y_test_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_var = X_train_c_pca.shape[1]\n",
    "num_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_multiple_reg: 0.0627\n"
     ]
    }
   ],
   "source": [
    "multiple_reg = LinearRegression().fit(X_train_pca, y_train)\n",
    "score_multiple_reg = multiple_reg.score(X_test_pca, y_test)\n",
    "\n",
    "print('score_multiple_reg:', \"%.4f\" % score_multiple_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['multi_linear'] = multiple_reg.coef_\n",
    "REGRESSOR_ACCURACY_DICT['multi_linear'] = score_multiple_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 1\n"
     ]
    }
   ],
   "source": [
    "# testing for different max depth\n",
    "rfc = dict()\n",
    "for i in range (1, 15):\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "    y_pred = clf.predict(X_val_c_pca)\n",
    "    score_clf = accuracy_score(y_val_c, y_pred)\n",
    "    rfc[i] = score_clf\n",
    "\n",
    "max_depth = max(rfc, key=rfc.get)\n",
    "print('max depth:', max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_rf_clf: 0.7059\n"
     ]
    }
   ],
   "source": [
    "# choose max_depth = 4\n",
    "rf_clf = RandomForestClassifier(max_depth=int(max_depth), random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_rf_clf = rf_clf.score(X_test_c_pca, y_test_c)\n",
    "print('score_rf_clf:', \"%.4f\" % score_rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['random_forest'] = rf_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['random_forest'] = score_rf_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_rf_reg: 0.0434\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor().fit(X_train_pca, y_train)\n",
    "score_rf_reg = rf_reg.score(X_test_pca, y_test)\n",
    "print('score_rf_reg:', \"%.4f\" % score_rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['random_forest'] = rf_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['random_forest'] = score_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logistic: 0.6941\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(penalty = 'l1', solver='liblinear', random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_logistic = logistic_reg.score(X_test_c_pca, y_test_c)\n",
    "print('score_logistic:', \"%.4f\" % score_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['logistic'] = logistic_reg.coef_[0]\n",
    "CLASSIFIER_ACCURACY_DICT['logistic'] = score_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529411764705883"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gra_clf = GradientBoostingClassifier(n_estimators = 200, learning_rate=0.50, max_depth=5, random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_gb_clf = gra_clf.score(X_test_c_pca, y_test_c)\n",
    "score_gb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['gradient_boosting'] = gra_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['gradient_boosting'] = score_gb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1265636871768412"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gra_reg = GradientBoostingRegressor(random_state=0).fit(X_train_pca, y_train)\n",
    "score_gb_reg = gra_reg.score(X_test_pca, y_test)\n",
    "score_gb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['gradient_boosting'] = gra_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['gradient_boosting'] = score_gb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:07:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49411764705882355"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False).fit(X_train_c_pca, y_train_c)\n",
    "score_xgb_clf = xgb_clf.score(X_test_c_pca, y_test_c)\n",
    "score_xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['xgboost'] = xgb_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['xgboost'] = score_xgb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22637460406135834"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg = XGBRegressor(random_state = 0).fit(X_train_pca, y_train)\n",
    "score_xgb_reg = xgb_reg.score(X_test_pca, y_test)\n",
    "score_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['xgboost'] = xgb_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['xgboost'] = score_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6352941176470588"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb_clf = AdaBoostClassifier().fit(X_train_c_pca, y_train_c)\n",
    "score_adb_clf = adb_clf.score(X_test_c_pca, y_test_c)\n",
    "score_adb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['adaboost'] = adb_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['adaboost'] = score_adb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01389118867280481"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb_reg = AdaBoostRegressor().fit(X_train_pca, y_train)\n",
    "score_adb_reg = adb_reg.score(X_test_pca, y_test)\n",
    "score_adb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['adaboost'] = adb_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['adaboost'] = score_adb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294117647058823\n",
      "0.6705882352941176\n",
      "0.6588235294117647\n"
     ]
    }
   ],
   "source": [
    "# Try different kernels\n",
    "kernels = ('linear', 'poly', 'rbf')\n",
    "\n",
    "for k in kernels:\n",
    "    svm_clf = SVC(kernel=k).fit(X_train_c_pca, y_train_c)\n",
    "    y_pred = svm_clf.predict(X_test_c_pca)\n",
    "    vars()[f'score_svc_{k}']= accuracy_score(y_test_c, y_pred)\n",
    "    \n",
    "    if k == 'linear':\n",
    "        CLASSIFIER_COEF_DICT['svc_linear'] = svm_clf.coef_[0]\n",
    "    \n",
    "print(score_svc_linear)\n",
    "print(score_svc_poly)\n",
    "print(score_svc_rbf)\n",
    "\n",
    "CLASSIFIER_ACCURACY_DICT['svc_linear'] = score_svc_linear\n",
    "CLASSIFIER_ACCURACY_DICT['svc_poly'] = score_svc_poly\n",
    "CLASSIFIER_ACCURACY_DICT['svc_rbf'] = score_svc_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294117647058823\n"
     ]
    }
   ],
   "source": [
    "gnb_clf = GaussianNB().fit(X_train_c_pca, y_train_c)\n",
    "score_gnb = gnb_clf.score(X_test_c_pca, y_test_c)\n",
    "print(score_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_ACCURACY_DICT['GaussianNB'] = score_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuro networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 0.7431 - accuracy: 0.4751 - val_loss: 0.7929 - val_accuracy: 0.4353\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.4909 - val_loss: 0.7788 - val_accuracy: 0.4471\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7330 - accuracy: 0.4707 - val_loss: 0.7682 - val_accuracy: 0.4824\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.4897 - val_loss: 0.7567 - val_accuracy: 0.4706\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5285 - val_loss: 0.7480 - val_accuracy: 0.4706\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.4891 - val_loss: 0.7383 - val_accuracy: 0.4588\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.5474 - val_loss: 0.7323 - val_accuracy: 0.4588\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.5110 - val_loss: 0.7259 - val_accuracy: 0.4588\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5758 - val_loss: 0.7209 - val_accuracy: 0.4588\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5391 - val_loss: 0.7153 - val_accuracy: 0.4588\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.5842 - val_loss: 0.7110 - val_accuracy: 0.4471\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5729 - val_loss: 0.7063 - val_accuracy: 0.4471\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6025 - val_loss: 0.7021 - val_accuracy: 0.4588\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5881 - val_loss: 0.6975 - val_accuracy: 0.4706\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5918 - val_loss: 0.6940 - val_accuracy: 0.4824\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6097 - val_loss: 0.6923 - val_accuracy: 0.5059\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6110 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6107 - val_loss: 0.6867 - val_accuracy: 0.5176\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.5867 - val_loss: 0.6835 - val_accuracy: 0.5176\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6085 - val_loss: 0.6819 - val_accuracy: 0.5294\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6044 - val_loss: 0.6796 - val_accuracy: 0.5294\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6161 - val_loss: 0.6775 - val_accuracy: 0.5294\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5646 - val_loss: 0.6758 - val_accuracy: 0.5412\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.5966 - val_loss: 0.6743 - val_accuracy: 0.5412\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.5950 - val_loss: 0.6735 - val_accuracy: 0.5412\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.5932 - val_loss: 0.6729 - val_accuracy: 0.5412\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6079 - val_loss: 0.6730 - val_accuracy: 0.5529\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.5886 - val_loss: 0.6721 - val_accuracy: 0.5765\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6027 - val_loss: 0.6712 - val_accuracy: 0.5765\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.5807 - val_loss: 0.6697 - val_accuracy: 0.5882\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.5749 - val_loss: 0.6676 - val_accuracy: 0.5882\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6343 - val_loss: 0.6669 - val_accuracy: 0.5882\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6123 - val_loss: 0.6650 - val_accuracy: 0.5882\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6268 - val_loss: 0.6651 - val_accuracy: 0.5882\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6183 - val_loss: 0.6632 - val_accuracy: 0.5882\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6252 - val_loss: 0.6631 - val_accuracy: 0.5882\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.5919 - val_loss: 0.6621 - val_accuracy: 0.5882\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6463 - val_loss: 0.6617 - val_accuracy: 0.5882\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.5929 - val_loss: 0.6616 - val_accuracy: 0.6000\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6321 - val_loss: 0.6613 - val_accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6289 - val_loss: 0.6612 - val_accuracy: 0.6000\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6350 - val_loss: 0.6614 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6256 - val_loss: 0.6604 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6334 - val_loss: 0.6591 - val_accuracy: 0.6000\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6568 - val_loss: 0.6588 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6178 - val_loss: 0.6565 - val_accuracy: 0.6118\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.5926 - val_loss: 0.6564 - val_accuracy: 0.6118\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6317 - val_loss: 0.6561 - val_accuracy: 0.6118\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6635 - val_loss: 0.6552 - val_accuracy: 0.6235\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6552 - val_loss: 0.6554 - val_accuracy: 0.6235\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10, input_dim=num_var, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_c_pca, y_train_c, epochs=50, validation_data=(X_val_c_pca, y_val_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6824\n",
      "0.6823529601097107\n"
     ]
    }
   ],
   "source": [
    "loss, score_neuro = model.evaluate(X_test_c_pca, y_test_c)\n",
    "print(score_neuro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_ACCURACY_DICT['neuro'] = score_neuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression models</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multi_linear</th>\n",
       "      <td>0.062738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>-0.126564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>-0.226375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.013891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Regression models          \n",
       "multi_linear       0.062738\n",
       "random_forest      0.043392\n",
       "gradient_boosting -0.126564\n",
       "xgboost           -0.226375\n",
       "adaboost           0.013891"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df = pd.DataFrame.from_dict(REGRESSOR_ACCURACY_DICT , orient='index', columns=['Score'])\n",
    "reg_df.index.name = 'Regression models'\n",
    "#reg_df.sort_values(by=['Score'], ascending=False)\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier models</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>0.552941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.494118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_linear</th>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_poly</th>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>0.658824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuro</th>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Classifier models          \n",
       "random_forest      0.705882\n",
       "logistic           0.694118\n",
       "gradient_boosting  0.552941\n",
       "xgboost            0.494118\n",
       "adaboost           0.635294\n",
       "svc_linear         0.729412\n",
       "svc_poly           0.670588\n",
       "svc_rbf            0.658824\n",
       "GaussianNB         0.729412\n",
       "neuro              0.682353"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_df = pd.DataFrame.from_dict(CLASSIFIER_ACCURACY_DICT, orient='index',columns=['Score'])\n",
    "clf_df.index.name = 'Classifier models'\n",
    "#clf_df.sort_values(by=['Score'], ascending=False)\n",
    "clf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multi_linear</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.088414</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.084296</td>\n",
       "      <td>0.161635</td>\n",
       "      <td>0.144336</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.095099</td>\n",
       "      <td>0.127326</td>\n",
       "      <td>0.110356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>0.051986</td>\n",
       "      <td>0.102827</td>\n",
       "      <td>0.100148</td>\n",
       "      <td>0.139598</td>\n",
       "      <td>0.126079</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>0.126752</td>\n",
       "      <td>0.160945</td>\n",
       "      <td>0.103027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.099284</td>\n",
       "      <td>0.124519</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.115591</td>\n",
       "      <td>0.115074</td>\n",
       "      <td>0.109446</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.118692</td>\n",
       "      <td>0.108731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.120334</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.176476</td>\n",
       "      <td>0.183748</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>0.098821</td>\n",
       "      <td>0.124682</td>\n",
       "      <td>0.079818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4         5  \\\n",
       "multi_linear       0.000016  0.000020 -0.000045  0.000293 -0.000360 -0.000165   \n",
       "random_forest      0.088414  0.095668  0.084296  0.161635  0.144336  0.092870   \n",
       "gradient_boosting  0.051986  0.102827  0.100148  0.139598  0.126079  0.088638   \n",
       "xgboost            0.099284  0.124519  0.082115  0.115591  0.115074  0.109446   \n",
       "adaboost           0.027910  0.120334  0.056101  0.176476  0.183748  0.132110   \n",
       "\n",
       "                          6         7         8  \n",
       "multi_linear       0.000032  0.000453  0.000269  \n",
       "random_forest      0.095099  0.127326  0.110356  \n",
       "gradient_boosting  0.126752  0.160945  0.103027  \n",
       "xgboost            0.126549  0.118692  0.108731  \n",
       "adaboost           0.098821  0.124682  0.079818  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_coef_df = pd.DataFrame.from_dict(REGRESSOR_COEF_DICT, orient='index')\n",
    "reg_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.002371</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>-0.201637</td>\n",
       "      <td>0.208744</td>\n",
       "      <td>-0.423214</td>\n",
       "      <td>-0.178593</td>\n",
       "      <td>0.143575</td>\n",
       "      <td>0.645465</td>\n",
       "      <td>0.209227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>0.092015</td>\n",
       "      <td>0.072457</td>\n",
       "      <td>0.095273</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>0.095543</td>\n",
       "      <td>0.107766</td>\n",
       "      <td>0.089106</td>\n",
       "      <td>0.216731</td>\n",
       "      <td>0.128470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.089967</td>\n",
       "      <td>0.113825</td>\n",
       "      <td>0.115103</td>\n",
       "      <td>0.105873</td>\n",
       "      <td>0.109381</td>\n",
       "      <td>0.089211</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>0.131004</td>\n",
       "      <td>0.130785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_linear</th>\n",
       "      <td>0.001986</td>\n",
       "      <td>-0.008169</td>\n",
       "      <td>-0.254268</td>\n",
       "      <td>0.379269</td>\n",
       "      <td>-0.490410</td>\n",
       "      <td>-0.201220</td>\n",
       "      <td>0.168047</td>\n",
       "      <td>0.790169</td>\n",
       "      <td>0.437013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4         5  \\\n",
       "random_forest      0.020000  0.040000  0.040000  0.130000  0.330000  0.050000   \n",
       "logistic           0.002371 -0.013184 -0.201637  0.208744 -0.423214 -0.178593   \n",
       "gradient_boosting  0.092015  0.072457  0.095273  0.102639  0.095543  0.107766   \n",
       "xgboost            0.089967  0.113825  0.115103  0.105873  0.109381  0.089211   \n",
       "adaboost           0.120000  0.140000  0.100000  0.080000  0.080000  0.120000   \n",
       "svc_linear         0.001986 -0.008169 -0.254268  0.379269 -0.490410 -0.201220   \n",
       "\n",
       "                          6         7         8  \n",
       "random_forest      0.040000  0.270000  0.080000  \n",
       "logistic           0.143575  0.645465  0.209227  \n",
       "gradient_boosting  0.089106  0.216731  0.128470  \n",
       "xgboost            0.114850  0.131004  0.130785  \n",
       "adaboost           0.140000  0.100000  0.120000  \n",
       "svc_linear         0.168047  0.790169  0.437013  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_coef_df = pd.DataFrame.from_dict(CLASSIFIER_COEF_DICT, orient='index')\n",
    "clf_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "book = load_workbook('Results.xlsx')\n",
    "writer = pd.ExcelWriter('Results.xlsx', engine='openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "reg_df.to_excel(writer, sheet_name='%s reg score' % sheetname)\n",
    "clf_df.to_excel(writer, sheet_name='%s clf score' % sheetname)\n",
    "reg_coef_df.to_excel(writer, sheet_name='%s reg coef' % sheetname)\n",
    "clf_coef_df.to_excel(writer, sheet_name='%s clf coef' % sheetname)\n",
    "\n",
    "writer.save()\n",
    "#reg_df.to_csv('reg_df.csv')\n",
    "#clf_df.to_csv('clf_df.csv')\n",
    "#reg_coef_df.to_csv('reg_coef_df.csv')\n",
    "#clf_coef_df.to_csv('clf_coef_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
